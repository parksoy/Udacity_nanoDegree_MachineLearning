{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n",
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n",
      "Build model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_1 (LSTM)                    (None, 128)           72192       lstm_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "repeatvector_1 (RepeatVector)    (None, 4, 128)        0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 4, 128)        131584      repeatvector_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistribut (None, 4, 12)         1548        lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 4, 12)         0           timedistributed_1[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 54s - loss: 1.8395 - acc: 0.3352 - val_loss: 1.7130 - val_acc: 0.3680\n",
      "Q 49+72  \n",
      "T 121 \n",
      "\u001b[91m☒\u001b[0m 11  \n",
      "---\n",
      "Q 259+277\n",
      "T 536 \n",
      "\u001b[91m☒\u001b[0m 122 \n",
      "---\n",
      "Q 333+407\n",
      "T 740 \n",
      "\u001b[91m☒\u001b[0m 111 \n",
      "---\n",
      "Q 1+975  \n",
      "T 976 \n",
      "\u001b[91m☒\u001b[0m 119 \n",
      "---\n",
      "Q 152+896\n",
      "T 1048\n",
      "\u001b[91m☒\u001b[0m 122 \n",
      "---\n",
      "Q 779+18 \n",
      "T 797 \n",
      "\u001b[91m☒\u001b[0m 909 \n",
      "---\n",
      "Q 99+142 \n",
      "T 241 \n",
      "\u001b[91m☒\u001b[0m 901 \n",
      "---\n",
      "Q 37+87  \n",
      "T 124 \n",
      "\u001b[91m☒\u001b[0m 189 \n",
      "---\n",
      "Q 309+21 \n",
      "T 330 \n",
      "\u001b[91m☒\u001b[0m 391 \n",
      "---\n",
      "Q 741+364\n",
      "T 1105\n",
      "\u001b[91m☒\u001b[0m 1011\n",
      "---\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 58s - loss: 1.6271 - acc: 0.3959 - val_loss: 1.5321 - val_acc: 0.4318\n",
      "Q 664+97 \n",
      "T 761 \n",
      "\u001b[91m☒\u001b[0m 701 \n",
      "---\n",
      "Q 477+7  \n",
      "T 484 \n",
      "\u001b[91m☒\u001b[0m 777 \n",
      "---\n",
      "Q 42+502 \n",
      "T 544 \n",
      "\u001b[91m☒\u001b[0m 476 \n",
      "---\n",
      "Q 748+129\n",
      "T 877 \n",
      "\u001b[91m☒\u001b[0m 806 \n",
      "---\n",
      "Q 564+184\n",
      "T 748 \n",
      "\u001b[91m☒\u001b[0m 601 \n",
      "---\n",
      "Q 0+662  \n",
      "T 662 \n",
      "\u001b[91m☒\u001b[0m 676 \n",
      "---\n",
      "Q 85+751 \n",
      "T 836 \n",
      "\u001b[91m☒\u001b[0m 801 \n",
      "---\n",
      "Q 490+963\n",
      "T 1453\n",
      "\u001b[91m☒\u001b[0m 1421\n",
      "---\n",
      "Q 27+3   \n",
      "T 30  \n",
      "\u001b[91m☒\u001b[0m 13  \n",
      "---\n",
      "Q 7+604  \n",
      "T 611 \n",
      "\u001b[91m☒\u001b[0m 776 \n",
      "---\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 52s - loss: 1.4288 - acc: 0.4668 - val_loss: 1.3320 - val_acc: 0.5085\n",
      "Q 358+71 \n",
      "T 429 \n",
      "\u001b[91m☒\u001b[0m 488 \n",
      "---\n",
      "Q 8+125  \n",
      "T 133 \n",
      "\u001b[91m☒\u001b[0m 118 \n",
      "---\n",
      "Q 682+7  \n",
      "T 689 \n",
      "\u001b[91m☒\u001b[0m 788 \n",
      "---\n",
      "Q 31+282 \n",
      "T 313 \n",
      "\u001b[91m☒\u001b[0m 388 \n",
      "---\n",
      "Q 8+362  \n",
      "T 370 \n",
      "\u001b[91m☒\u001b[0m 368 \n",
      "---\n",
      "Q 738+1  \n",
      "T 739 \n",
      "\u001b[91m☒\u001b[0m 734 \n",
      "---\n",
      "Q 34+730 \n",
      "T 764 \n",
      "\u001b[91m☒\u001b[0m 780 \n",
      "---\n",
      "Q 87+89  \n",
      "T 176 \n",
      "\u001b[91m☒\u001b[0m 184 \n",
      "---\n",
      "Q 606+0  \n",
      "T 606 \n",
      "\u001b[91m☒\u001b[0m 660 \n",
      "---\n",
      "Q 37+553 \n",
      "T 590 \n",
      "\u001b[91m☒\u001b[0m 698 \n",
      "---\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 52s - loss: 1.2616 - acc: 0.5336 - val_loss: 1.1906 - val_acc: 0.5613\n",
      "Q 824+307\n",
      "T 1131\n",
      "\u001b[91m☒\u001b[0m 1165\n",
      "---\n",
      "Q 606+584\n",
      "T 1190\n",
      "\u001b[91m☒\u001b[0m 1222\n",
      "---\n",
      "Q 83+512 \n",
      "T 595 \n",
      "\u001b[91m☒\u001b[0m 696 \n",
      "---\n",
      "Q 7+98   \n",
      "T 105 \n",
      "\u001b[91m☒\u001b[0m 90  \n",
      "---\n",
      "Q 651+145\n",
      "T 796 \n",
      "\u001b[91m☒\u001b[0m 707 \n",
      "---\n",
      "Q 986+7  \n",
      "T 993 \n",
      "\u001b[91m☒\u001b[0m 990 \n",
      "---\n",
      "Q 572+50 \n",
      "T 622 \n",
      "\u001b[91m☒\u001b[0m 620 \n",
      "---\n",
      "Q 3+656  \n",
      "T 659 \n",
      "\u001b[91m☒\u001b[0m 661 \n",
      "---\n",
      "Q 727+46 \n",
      "T 773 \n",
      "\u001b[91m☒\u001b[0m 777 \n",
      "---\n",
      "Q 69+11  \n",
      "T 80  \n",
      "\u001b[91m☒\u001b[0m 70  \n",
      "---\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 54s - loss: 1.1206 - acc: 0.5900 - val_loss: 1.0680 - val_acc: 0.6078\n",
      "Q 111+34 \n",
      "T 145 \n",
      "\u001b[92m☑\u001b[0m 145 \n",
      "---\n",
      "Q 72+615 \n",
      "T 687 \n",
      "\u001b[91m☒\u001b[0m 780 \n",
      "---\n",
      "Q 924+0  \n",
      "T 924 \n",
      "\u001b[91m☒\u001b[0m 933 \n",
      "---\n",
      "Q 61+233 \n",
      "T 294 \n",
      "\u001b[91m☒\u001b[0m 385 \n",
      "---\n",
      "Q 590+21 \n",
      "T 611 \n",
      "\u001b[91m☒\u001b[0m 600 \n",
      "---\n",
      "Q 29+465 \n",
      "T 494 \n",
      "\u001b[91m☒\u001b[0m 490 \n",
      "---\n",
      "Q 167+642\n",
      "T 809 \n",
      "\u001b[91m☒\u001b[0m 805 \n",
      "---\n",
      "Q 364+763\n",
      "T 1127\n",
      "\u001b[91m☒\u001b[0m 1100\n",
      "---\n",
      "Q 9+143  \n",
      "T 152 \n",
      "\u001b[91m☒\u001b[0m 145 \n",
      "---\n",
      "Q 85+30  \n",
      "T 115 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 50s - loss: 1.0080 - acc: 0.6327 - val_loss: 0.9592 - val_acc: 0.6503\n",
      "Q 795+732\n",
      "T 1527\n",
      "\u001b[91m☒\u001b[0m 1511\n",
      "---\n",
      "Q 81+67  \n",
      "T 148 \n",
      "\u001b[91m☒\u001b[0m 141 \n",
      "---\n",
      "Q 401+918\n",
      "T 1319\n",
      "\u001b[91m☒\u001b[0m 1334\n",
      "---\n",
      "Q 258+24 \n",
      "T 282 \n",
      "\u001b[91m☒\u001b[0m 285 \n",
      "---\n",
      "Q 354+9  \n",
      "T 363 \n",
      "\u001b[92m☑\u001b[0m 363 \n",
      "---\n",
      "Q 89+604 \n",
      "T 693 \n",
      "\u001b[91m☒\u001b[0m 603 \n",
      "---\n",
      "Q 184+369\n",
      "T 553 \n",
      "\u001b[91m☒\u001b[0m 554 \n",
      "---\n",
      "Q 19+195 \n",
      "T 214 \n",
      "\u001b[91m☒\u001b[0m 219 \n",
      "---\n",
      "Q 397+8  \n",
      "T 405 \n",
      "\u001b[91m☒\u001b[0m 403 \n",
      "---\n",
      "Q 210+405\n",
      "T 615 \n",
      "\u001b[91m☒\u001b[0m 533 \n",
      "---\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 53s - loss: 0.9078 - acc: 0.6757 - val_loss: 0.8689 - val_acc: 0.6881\n",
      "Q 25+40  \n",
      "T 65  \n",
      "\u001b[91m☒\u001b[0m 55  \n",
      "---\n",
      "Q 76+749 \n",
      "T 825 \n",
      "\u001b[91m☒\u001b[0m 821 \n",
      "---\n",
      "Q 580+858\n",
      "T 1438\n",
      "\u001b[91m☒\u001b[0m 1427\n",
      "---\n",
      "Q 73+873 \n",
      "T 946 \n",
      "\u001b[91m☒\u001b[0m 958 \n",
      "---\n",
      "Q 801+551\n",
      "T 1352\n",
      "\u001b[91m☒\u001b[0m 1377\n",
      "---\n",
      "Q 58+406 \n",
      "T 464 \n",
      "\u001b[91m☒\u001b[0m 463 \n",
      "---\n",
      "Q 230+6  \n",
      "T 236 \n",
      "\u001b[91m☒\u001b[0m 336 \n",
      "---\n",
      "Q 91+65  \n",
      "T 156 \n",
      "\u001b[91m☒\u001b[0m 159 \n",
      "---\n",
      "Q 135+93 \n",
      "T 228 \n",
      "\u001b[92m☑\u001b[0m 228 \n",
      "---\n",
      "Q 46+487 \n",
      "T 533 \n",
      "\u001b[92m☑\u001b[0m 533 \n",
      "---\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 53s - loss: 0.8256 - acc: 0.7062 - val_loss: 0.7805 - val_acc: 0.7230\n",
      "Q 118+3  \n",
      "T 121 \n",
      "\u001b[91m☒\u001b[0m 129 \n",
      "---\n",
      "Q 234+10 \n",
      "T 244 \n",
      "\u001b[91m☒\u001b[0m 236 \n",
      "---\n",
      "Q 656+38 \n",
      "T 694 \n",
      "\u001b[91m☒\u001b[0m 691 \n",
      "---\n",
      "Q 374+47 \n",
      "T 421 \n",
      "\u001b[92m☑\u001b[0m 421 \n",
      "---\n",
      "Q 496+658\n",
      "T 1154\n",
      "\u001b[91m☒\u001b[0m 1141\n",
      "---\n",
      "Q 2+708  \n",
      "T 710 \n",
      "\u001b[91m☒\u001b[0m 701 \n",
      "---\n",
      "Q 56+382 \n",
      "T 438 \n",
      "\u001b[91m☒\u001b[0m 434 \n",
      "---\n",
      "Q 70+852 \n",
      "T 922 \n",
      "\u001b[91m☒\u001b[0m 926 \n",
      "---\n",
      "Q 806+90 \n",
      "T 896 \n",
      "\u001b[91m☒\u001b[0m 886 \n",
      "---\n",
      "Q 67+45  \n",
      "T 112 \n",
      "\u001b[92m☑\u001b[0m 112 \n",
      "---\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 57s - loss: 0.7108 - acc: 0.7422 - val_loss: 0.6338 - val_acc: 0.7683\n",
      "Q 398+8  \n",
      "T 406 \n",
      "\u001b[91m☒\u001b[0m 306 \n",
      "---\n",
      "Q 987+16 \n",
      "T 1003\n",
      "\u001b[91m☒\u001b[0m 1014\n",
      "---\n",
      "Q 393+740\n",
      "T 1133\n",
      "\u001b[91m☒\u001b[0m 1125\n",
      "---\n",
      "Q 930+38 \n",
      "T 968 \n",
      "\u001b[91m☒\u001b[0m 969 \n",
      "---\n",
      "Q 731+663\n",
      "T 1394\n",
      "\u001b[91m☒\u001b[0m 1485\n",
      "---\n",
      "Q 69+21  \n",
      "T 90  \n",
      "\u001b[91m☒\u001b[0m 80  \n",
      "---\n",
      "Q 47+78  \n",
      "T 125 \n",
      "\u001b[92m☑\u001b[0m 125 \n",
      "---\n",
      "Q 96+93  \n",
      "T 189 \n",
      "\u001b[91m☒\u001b[0m 188 \n",
      "---\n",
      "Q 966+3  \n",
      "T 969 \n",
      "\u001b[91m☒\u001b[0m 968 \n",
      "---\n",
      "Q 61+857 \n",
      "T 918 \n",
      "\u001b[92m☑\u001b[0m 918 \n",
      "---\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 56s - loss: 0.5297 - acc: 0.8111 - val_loss: 0.4499 - val_acc: 0.8445\n",
      "Q 56+898 \n",
      "T 954 \n",
      "\u001b[92m☑\u001b[0m 954 \n",
      "---\n",
      "Q 18+295 \n",
      "T 313 \n",
      "\u001b[91m☒\u001b[0m 323 \n",
      "---\n",
      "Q 17+16  \n",
      "T 33  \n",
      "\u001b[91m☒\u001b[0m 42  \n",
      "---\n",
      "Q 807+669\n",
      "T 1476\n",
      "\u001b[91m☒\u001b[0m 1474\n",
      "---\n",
      "Q 747+613\n",
      "T 1360\n",
      "\u001b[91m☒\u001b[0m 1359\n",
      "---\n",
      "Q 235+987\n",
      "T 1222\n",
      "\u001b[91m☒\u001b[0m 1220\n",
      "---\n",
      "Q 327+165\n",
      "T 492 \n",
      "\u001b[91m☒\u001b[0m 592 \n",
      "---\n",
      "Q 379+8  \n",
      "T 387 \n",
      "\u001b[92m☑\u001b[0m 387 \n",
      "---\n",
      "Q 4+561  \n",
      "T 565 \n",
      "\u001b[91m☒\u001b[0m 566 \n",
      "---\n",
      "Q 17+743 \n",
      "T 760 \n",
      "\u001b[92m☑\u001b[0m 760 \n",
      "---\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 53s - loss: 0.3664 - acc: 0.8893 - val_loss: 0.3236 - val_acc: 0.9015\n",
      "Q 83+830 \n",
      "T 913 \n",
      "\u001b[91m☒\u001b[0m 904 \n",
      "---\n",
      "Q 70+10  \n",
      "T 80  \n",
      "\u001b[92m☑\u001b[0m 80  \n",
      "---\n",
      "Q 444+4  \n",
      "T 448 \n",
      "\u001b[92m☑\u001b[0m 448 \n",
      "---\n",
      "Q 0+544  \n",
      "T 544 \n",
      "\u001b[92m☑\u001b[0m 544 \n",
      "---\n",
      "Q 32+297 \n",
      "T 329 \n",
      "\u001b[91m☒\u001b[0m 320 \n",
      "---\n",
      "Q 59+658 \n",
      "T 717 \n",
      "\u001b[92m☑\u001b[0m 717 \n",
      "---\n",
      "Q 89+799 \n",
      "T 888 \n",
      "\u001b[92m☑\u001b[0m 888 \n",
      "---\n",
      "Q 272+696\n",
      "T 968 \n",
      "\u001b[91m☒\u001b[0m 978 \n",
      "---\n",
      "Q 681+92 \n",
      "T 773 \n",
      "\u001b[92m☑\u001b[0m 773 \n",
      "---\n",
      "Q 80+849 \n",
      "T 929 \n",
      "\u001b[92m☑\u001b[0m 929 \n",
      "---\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "23936/45000 [==============>...............] - ETA: 25s - loss: 0.2805 - acc: 0.9271"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e407cfbd0f72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     model.fit(X_train, y_train, batch_size=BATCH_SIZE, nb_epoch=1,\n\u001b[0;32m--> 183\u001b[0;31m               validation_data=(X_val, y_val))\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Select 10 samples from the validation set at random so we can visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/parksoy/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/parksoy/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1190\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/parksoy/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/parksoy/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1898\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1900\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1901\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/parksoy/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 372\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    373\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/parksoy/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 636\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    637\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/parksoy/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 708\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/parksoy/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    713\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/parksoy/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''An implementation of sequence to sequence learning for performing addition\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "Input may optionally be inverted, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "\n",
    "Two digits inverted:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "Three digits inverted:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "Four digits inverted:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "Five digits inverted:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.engine.training import slice_X\n",
    "from keras.layers import Activation, TimeDistributed, Dense, RepeatVector, recurrent\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "\n",
    "\n",
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        X = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            X[i, self.char_indices[c]] = 1\n",
    "        return X\n",
    "\n",
    "    def decode(self, X, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            X = X.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in X)\n",
    "\n",
    "\n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "INVERT = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that X+Y == Y+X (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if INVERT:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))\n",
    "\n",
    "print('Vectorization...')\n",
    "X = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    X[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (X, y) in unison as the later parts of X will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(X) - len(X) // 10\n",
    "(X_train, X_val) = (slice_X(X, 0, split_at), slice_X(X, split_at))\n",
    "(y_train, y_val) = (y[:split_at], y[split_at:])\n",
    "\n",
    "print('Training Data:')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = recurrent.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, nb_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(RepeatVector(DIGITS + 1))\n",
    "\n",
    "\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (nb_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(TimeDistributed(Dense(len(chars))))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(X_train, y_train, batch_size=BATCH_SIZE, nb_epoch=1,\n",
    "              validation_data=(X_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(X_val))\n",
    "        rowX, rowy = X_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowX, verbose=0)\n",
    "        q = ctable.decode(rowX[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if INVERT else q)\n",
    "        print('T', correct)\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=\" \")\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=\" \")\n",
    "        print(guess)\n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
