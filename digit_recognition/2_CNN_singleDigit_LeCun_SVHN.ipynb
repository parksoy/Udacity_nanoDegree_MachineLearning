{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SVHN single digit images and create ckpt model.\n",
    "\n",
    "This is copied from https://github.com/hangyao/street_view_house_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = 'SVHN.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  #train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  #print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  #print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  #print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = 'SVHN1.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset1 = save['train_dataset1']\n",
    "  del save  # hint to help gc free up memory\n",
    "\n",
    "pickle_file = 'SVHN2.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset2 = save['train_dataset2']\n",
    "  del save  # hint to help gc free up memory\n",
    "\n",
    "pickle_file = 'SVHN3.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset3 = save['train_dataset3']\n",
    "  del save  # hint to help gc free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (598388, 32, 32) (598388,)\n",
      "Validation set (6000, 32, 32) (6000,)\n",
      "Test set (26032, 32, 32) (26032,)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = np.concatenate((train_dataset1, train_dataset2, train_dataset3), axis=0)\n",
    "del train_dataset1, train_dataset2, train_dataset3\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (598388, 32, 32, 1) (598388,)\n",
      "Validation set (6000, 32, 32, 1) (6000,)\n",
      "Test set (26032, 32, 32, 1) (26032,)\n"
     ]
    }
   ],
   "source": [
    "image_size = 32\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = labels.astype(np.int32)\n",
    "  return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LecunLCN(X, image_shape, threshold=1e-4, radius=7, use_divisor=True):\n",
    "    \"\"\"Local Contrast Normalization\"\"\"\n",
    "    \"\"\"[http://yann.lecun.com/exdb/publis/pdf/jarrett-iccv-09.pdf]\"\"\"\n",
    "\n",
    "    # Get Gaussian filter\n",
    "    filter_shape = (radius, radius, image_shape[3], 1)\n",
    "\n",
    "    #self.filters = theano.shared(self.gaussian_filter(filter_shape), borrow=True)\n",
    "    filters = gaussian_filter(filter_shape)\n",
    "    X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "    # Compute the Guassian weighted average by means of convolution\n",
    "    convout = tf.nn.conv2d(X, filters, [1,1,1,1], 'SAME')\n",
    "\n",
    "    # Subtractive step\n",
    "    mid = int(np.floor(filter_shape[1] / 2.))\n",
    "\n",
    "    # Make filter dimension broadcastable and subtract\n",
    "    centered_X = tf.sub(X, convout)\n",
    "\n",
    "    # Boolean marks whether or not to perform divisive step\n",
    "    if use_divisor:\n",
    "        # Note that the local variances can be computed by using the centered_X\n",
    "        # tensor. If we convolve this with the mean filter, that should give us\n",
    "        # the variance at each point. We simply take the square root to get our\n",
    "        # denominator\n",
    "\n",
    "        # Compute variances\n",
    "        sum_sqr_XX = tf.nn.conv2d(tf.square(centered_X), filters, [1,1,1,1], 'SAME')\n",
    "\n",
    "        # Take square root to get local standard deviation\n",
    "        denom = tf.sqrt(sum_sqr_XX)\n",
    "\n",
    "        per_img_mean = tf.reduce_mean(denom)\n",
    "        divisor = tf.maximum(per_img_mean, denom)\n",
    "        # Divisise step\n",
    "        new_X = tf.truediv(centered_X, tf.maximum(divisor, threshold))\n",
    "    else:\n",
    "        new_X = centered_X\n",
    "\n",
    "    return new_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gaussian_filter(kernel_shape):\n",
    "    x = np.zeros(kernel_shape, dtype = float)\n",
    "    mid = np.floor(kernel_shape[0] / 2.)\n",
    "    \n",
    "    for kernel_idx in xrange(0, kernel_shape[2]):\n",
    "        for i in xrange(0, kernel_shape[0]):\n",
    "            for j in xrange(0, kernel_shape[1]):\n",
    "                x[i, j, kernel_idx, 0] = gauss(i - mid, j - mid)\n",
    "    \n",
    "    return tf.convert_to_tensor(x / np.sum(x), dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss(x, y, sigma=3.0):\n",
    "    Z = 2 * np.pi * sigma ** 2\n",
    "    return  1. / Z * np.exp(-(x ** 2 + y ** 2) / (2. * sigma ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == labels)\n",
    "          / predictions.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "patch_size = 5\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 64\n",
    "num_hidden1 = 64\n",
    "num_hidden2 = 16\n",
    "shape=[batch_size, image_size, image_size, num_channels]\n",
    "\n",
    "# Construct a 7-layer CNN.\n",
    "# C1: convolutional layer, batch_size x 28 x 28 x 16, convolution size: 5 x 5 x 1 x 16\n",
    "# S2: sub-sampling layer, batch_size x 14 x 14 x 16\n",
    "# C3: convolutional layer, batch_size x 10 x 10 x 32, convolution size: 5 x 5 x 16 x 32\n",
    "# S4: sub-sampling layer, batch_size x 5 x 5 x 32\n",
    "# C5: convolutional layer, batch_size x 1 x 1 x 64, convolution size: 5 x 5 x 32 x 64\n",
    "# Dropout\n",
    "# F6: fully-connected layer, weight size: 64 x 16\n",
    "# Output layer, weight size: 16 x 10\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.int64, shape=(batch_size))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.get_variable(\"W1\", shape=[patch_size, patch_size, num_channels, depth1],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "  layer1_biases = tf.Variable(tf.constant(1.0, shape=[depth1]), name='B1')\n",
    "  layer2_weights = tf.get_variable(\"W2\", shape=[patch_size, patch_size, depth1, depth2],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth2]), name='B2')\n",
    "  layer3_weights = tf.get_variable(\"W3\", shape=[patch_size, patch_size, depth2, num_hidden1],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden1]), name='B3')\n",
    "  layer4_weights = tf.get_variable(\"W4\", shape=[num_hidden1, num_hidden2],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden2]), name='B4')\n",
    "  layer5_weights = tf.get_variable(\"W5\", shape=[num_hidden2, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "  layer5_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5')\n",
    "  \n",
    "  # Model.\n",
    "  def model(data, keep_prob, shape):\n",
    "    LCN = LecunLCN(data, shape)\n",
    "    conv = tf.nn.conv2d(LCN, layer1_weights, [1,1,1,1], 'VALID', name='C1')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    lrn = tf.nn.local_response_normalization(hidden)\n",
    "    sub = tf.nn.max_pool(lrn, [1,2,2,1], [1,2,2,1], 'SAME', name='S2')\n",
    "    conv = tf.nn.conv2d(sub, layer2_weights, [1,1,1,1], padding='VALID', name='C3')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    lrn = tf.nn.local_response_normalization(hidden)\n",
    "    sub = tf.nn.max_pool(lrn, [1,2,2,1], [1,2,2,1], 'SAME', name='S4')\n",
    "    conv = tf.nn.conv2d(sub, layer3_weights, [1,1,1,1], padding='VALID', name='C5')\n",
    "    hidden = tf.nn.relu(conv + layer3_biases)\n",
    "    hidden = tf.nn.dropout(hidden, keep_prob)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer4_weights) + layer4_biases)\n",
    "    return tf.matmul(hidden, layer5_weights) + layer5_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset, 0.9375, shape)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  # Optimizer.\n",
    "  #optimizer = tf.train.AdagradOptimizer(0.01).minimize(loss)\n",
    "  global_step = tf.Variable(0)\n",
    "  learning_rate = tf.train.exponential_decay(0.05, global_step, 10000, 0.95)\n",
    "  optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(model(tf_train_dataset, 1.0, shape))\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset, 1.0, shape))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset, 1.0, shape))\n",
    "    \n",
    "  saver = tf.train.Saver()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.598512\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 9.4%\n",
      "Minibatch loss at step 500: 2.257316\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: 0.665065\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 70.8%\n",
      "Minibatch loss at step 1500: 0.358391\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 84.3%\n",
      "Minibatch loss at step 2000: 0.175869\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 2500: 0.258150\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 3000: 0.268629\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 3500: 0.256934\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 4000: 0.423957\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss at step 4500: 0.123546\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 5000: 0.124985\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss at step 5500: 0.145508\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 6000: 0.246288\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 6500: 0.096517\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 7000: 0.116792\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 7500: 0.190159\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 8000: 0.189114\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 8500: 0.224078\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.4%\n",
      "Minibatch loss at step 9000: 0.277218\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 9500: 0.161515\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 10000: 0.244796\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 91.5%\n",
      "Minibatch loss at step 10500: 0.146307\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 11000: 0.165103\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 11500: 0.301819\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 12000: 0.287499\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 91.9%\n",
      "Minibatch loss at step 12500: 0.205682\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 91.6%\n",
      "Minibatch loss at step 13000: 0.130969\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 91.8%\n",
      "Minibatch loss at step 13500: 0.089093\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 91.7%\n",
      "Minibatch loss at step 14000: 0.085960\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 14500: 0.077363\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 15000: 0.099900\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 15500: 0.135202\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 16000: 0.100539\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 16500: 0.258062\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 92.0%\n",
      "Minibatch loss at step 17000: 0.040233\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.2%\n",
      "Minibatch loss at step 17500: 0.065649\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.3%\n",
      "Minibatch loss at step 18000: 0.366458\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 18500: 0.299456\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 19000: 0.140534\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 19500: 0.087628\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 20000: 0.095072\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 20500: 0.050936\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 21000: 0.041558\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 21500: 0.141345\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.6%\n",
      "Minibatch loss at step 22000: 0.151765\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 22500: 0.135330\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 23000: 0.281636\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 23500: 0.108729\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 24000: 0.095907\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 24500: 0.103549\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 25000: 0.174160\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 25500: 0.150408\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.4%\n",
      "Minibatch loss at step 26000: 0.332925\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.8%\n",
      "Minibatch loss at step 26500: 0.135831\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 92.5%\n",
      "Minibatch loss at step 27000: 0.199386\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 93.1%\n",
      "Minibatch loss at step 27500: 0.253110\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 28000: 0.263915\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 28500: 0.334332\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.3%\n",
      "Minibatch loss at step 29000: 0.093261\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 29500: 0.135874\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 30000: 0.166004\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 92.7%\n",
      "Minibatch loss at step 30500: 0.111849\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 31000: 0.095257\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 31500: 0.222755\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 32000: 0.122501\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 32500: 0.144937\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 33000: 0.145899\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 33500: 0.030638\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 34000: 0.158309\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 34500: 0.112993\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 92.9%\n",
      "Minibatch loss at step 35000: 0.044655\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 35500: 0.100435\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 36000: 0.030370\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 36500: 0.474980\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 37000: 0.210535\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 37500: 0.060104\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 38000: 0.067602\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.3%\n",
      "Minibatch loss at step 38500: 0.063005\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.3%\n",
      "Minibatch loss at step 39000: 0.050971\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 39500: 0.074514\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 40000: 0.066846\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.1%\n",
      "Minibatch loss at step 40500: 0.140868\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 41000: 0.095467\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.0%\n",
      "Minibatch loss at step 41500: 0.189137\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 42000: 0.058542\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.1%\n",
      "Minibatch loss at step 42500: 0.144466\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 43000: 0.053270\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 43500: 0.071797\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.1%\n",
      "Minibatch loss at step 44000: 0.148524\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 44500: 0.088458\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 45000: 0.084531\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 45500: 0.179085\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 46000: 0.155058\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 46500: 0.208068\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 47000: 0.064380\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 47500: 0.148694\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 48000: 0.065949\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 48500: 0.133277\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 49000: 0.029035\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 49500: 0.139357\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 50000: 0.079771\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 50500: 0.043555\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 51000: 0.074473\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 51500: 0.044234\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 52000: 0.089221\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 52500: 0.070771\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.3%\n",
      "Minibatch loss at step 53000: 0.028226\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.2%\n",
      "Minibatch loss at step 53500: 0.181925\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 54000: 0.119734\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 54500: 0.162891\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 55000: 0.188993\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 55500: 0.290419\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 56000: 0.169490\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 56500: 0.022006\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 57000: 0.052389\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 57500: 0.068416\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 58000: 0.445534\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 58500: 0.241230\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 59000: 0.127784\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 59500: 0.116780\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 60000: 0.100077\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.4%\n",
      "Minibatch loss at step 60500: 0.151508\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 61000: 0.019998\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 61500: 0.056336\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 62000: 0.253384\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 62500: 0.152951\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 63000: 0.429271\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 63500: 0.029260\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 64000: 0.046987\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.3%\n",
      "Minibatch loss at step 64500: 0.184343\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 65000: 0.243577\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 65500: 0.072894\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 66000: 0.030677\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 66500: 0.136912\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 67000: 0.088685\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 67500: 0.074986\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 68000: 0.047257\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 68500: 0.043202\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 69000: 0.047888\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 69500: 0.121391\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 70000: 0.116483\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 70500: 0.302313\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 71000: 0.127051\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 71500: 0.067882\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 72000: 0.234170\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.5%\n",
      "Minibatch loss at step 72500: 0.367573\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 73000: 0.110653\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 73500: 0.051955\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 74000: 0.305460\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 74500: 0.052202\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 75000: 0.069715\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 75500: 0.070280\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 76000: 0.181994\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 76500: 0.164084\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 77000: 0.091081\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 77500: 0.155628\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 78000: 0.094083\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 78500: 0.050668\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 79000: 0.109268\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 79500: 0.070745\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 80000: 0.013260\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 80500: 0.025423\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 81000: 0.080593\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 81500: 0.083480\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 82000: 0.157280\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 82500: 0.115134\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 83000: 0.047162\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 83500: 0.107148\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 84000: 0.262633\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 84500: 0.135720\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 85000: 0.039903\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 94.2%\n",
      "Minibatch loss at step 85500: 0.058313\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 86000: 0.027307\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.6%\n",
      "Minibatch loss at step 86500: 0.030262\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 87000: 0.157768\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 87500: 0.214623\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 88000: 0.043912\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 88500: 0.179354\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 89000: 0.214083\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 89500: 0.089846\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 90000: 0.130348\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 90500: 0.057924\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 91000: 0.179347\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 91500: 0.031228\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 92000: 0.023904\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.7%\n",
      "Minibatch loss at step 92500: 0.199793\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 93.8%\n",
      "Minibatch loss at step 93000: 0.226281\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 93500: 0.145958\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 94000: 0.008947\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 94500: 0.116100\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 95000: 0.047236\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 95500: 0.139278\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 96000: 0.049736\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 96500: 0.047142\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 97000: 0.441295\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 94.1%\n",
      "Minibatch loss at step 97500: 0.056133\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 98000: 0.029500\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 98500: 0.132035\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 94.0%\n",
      "Minibatch loss at step 99000: 0.371832\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 99500: 0.053020\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.9%\n",
      "Minibatch loss at step 100000: 0.033666\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 93.8%\n",
      "Test accuracy: 93.3%\n",
      "Model saved in file: CNN_1.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_steps = 100001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size)]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 500 == 0): \n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "  save_path = saver.save(session, \"CNN_1.ckpt\")\n",
    "  print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.678059\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 500: 2.266469\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1000: 2.256179\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 1500: 2.263827\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2000: 2.260786\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 2500: 2.179418\n",
      "Minibatch accuracy: 28.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3000: 2.287635\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 3500: 2.288907\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 4000: 2.235539\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 4500: 2.247823\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 5000: 2.259484\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 5500: 2.239007\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 6000: 2.211287\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 6500: 2.204298\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 7000: 2.250027\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 7500: 2.259688\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 8000: 2.236430\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 8500: 2.249298\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 9000: 2.186448\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 9500: 2.184315\n",
      "Minibatch accuracy: 28.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 10000: 2.243484\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 10500: 2.293895\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 11000: 2.249710\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 11500: 2.289381\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 12000: 2.296655\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 12500: 2.250206\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 13000: 2.206546\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 13500: 2.240623\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 14000: 2.241163\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 14500: 2.253004\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 15000: 2.284951\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 15500: 2.276183\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 16000: 2.251028\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 16500: 2.254296\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 17000: 2.280894\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 17500: 2.292358\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 18000: 2.227192\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 18500: 2.290859\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 19000: 2.247495\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 19500: 2.236022\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 20000: 2.247645\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 20500: 2.197541\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 21000: 2.251807\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 21500: 2.171992\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 22000: 2.227134\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 22500: 2.314557\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 23000: 2.266197\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 23500: 2.261250\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 24000: 2.258266\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 24500: 2.186206\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 25000: 2.236316\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 25500: 2.259838\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 26000: 2.327766\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 26500: 2.282430\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 27000: 2.224809\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 27500: 2.258006\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 28000: 2.204642\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 28500: 2.208312\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 29000: 2.269029\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 29500: 2.253352\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 30000: 2.208570\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 30500: 2.238811\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 31000: 2.206298\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 31500: 2.208864\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 32000: 2.284323\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 32500: 2.205082\n",
      "Minibatch accuracy: 28.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 33000: 2.159527\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 33500: 2.214416\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 34000: 2.284162\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 34500: 2.235612\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 35000: 2.293419\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 35500: 2.324072\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 36000: 2.218083\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 36500: 2.256327\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 37000: 2.202816\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 37500: 2.264082\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 38000: 2.246969\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 38500: 2.220096\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 39000: 2.269147\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 39500: 2.295524\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 40000: 2.324909\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 40500: 2.286513\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 41000: 2.194252\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 41500: 2.232729\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 42000: 2.263164\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 42500: 2.256814\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 43000: 2.255635\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 43500: 2.337133\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 44000: 2.276437\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 44500: 2.331714\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 45000: 2.281758\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 45500: 2.338076\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 46000: 2.241822\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 46500: 2.139853\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 47000: 2.247909\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 47500: 2.251632\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 48000: 2.233436\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 48500: 2.279377\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 49000: 2.206999\n",
      "Minibatch accuracy: 26.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 49500: 2.288909\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 50000: 2.226851\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 50500: 2.281085\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 51000: 2.239167\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 51500: 2.248960\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 52000: 2.232488\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 52500: 2.259566\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 53000: 2.303695\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 53500: 2.226216\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 54000: 2.276689\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 54500: 2.267783\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 55000: 2.209049\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 55500: 2.134332\n",
      "Minibatch accuracy: 28.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 56000: 2.190847\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 56500: 2.312745\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 57000: 2.310302\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 57500: 2.332608\n",
      "Minibatch accuracy: 4.7%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 58000: 2.238897\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 58500: 2.229566\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 59000: 2.234611\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 59500: 2.159260\n",
      "Minibatch accuracy: 26.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 60000: 2.262275\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 60500: 2.272770\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 61000: 2.243166\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 61500: 2.296490\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 62000: 2.311170\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 62500: 2.272415\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 63000: 2.278369\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 63500: 2.261829\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 64000: 2.217745\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 64500: 2.236307\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 65000: 2.320076\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 65500: 2.219379\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 66000: 2.256064\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 66500: 2.213715\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 67000: 2.304091\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 67500: 2.232603\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 68000: 2.233164\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 68500: 2.190966\n",
      "Minibatch accuracy: 26.6%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 69000: 2.189557\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 69500: 2.264560\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 70000: 2.223422\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 15.3%\n",
      "Minibatch loss at step 70500: 2.028108\n",
      "Minibatch accuracy: 32.8%\n",
      "Validation accuracy: 21.4%\n",
      "Minibatch loss at step 71000: 1.674273\n",
      "Minibatch accuracy: 40.6%\n",
      "Validation accuracy: 28.8%\n",
      "Minibatch loss at step 71500: 1.535310\n",
      "Minibatch accuracy: 54.7%\n",
      "Validation accuracy: 40.3%\n",
      "Minibatch loss at step 72000: 1.561409\n",
      "Minibatch accuracy: 46.9%\n",
      "Validation accuracy: 53.1%\n",
      "Minibatch loss at step 72500: 1.328222\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 60.9%\n",
      "Minibatch loss at step 73000: 0.931696\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 67.0%\n",
      "Minibatch loss at step 73500: 0.934917\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 71.2%\n",
      "Minibatch loss at step 74000: 1.026630\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 73.5%\n",
      "Minibatch loss at step 74500: 0.728612\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 76.0%\n",
      "Minibatch loss at step 75000: 0.555032\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 75500: 0.520395\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 76000: 0.538794\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 76500: 0.464161\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 77000: 0.516745\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 77500: 0.533426\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 78000: 0.383750\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 78500: 0.480536\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 79000: 0.346537\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 83.1%\n",
      "Minibatch loss at step 79500: 0.597538\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.4%\n",
      "Minibatch loss at step 80000: 0.253356\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 83.5%\n",
      "Minibatch loss at step 80500: 0.269908\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 83.8%\n",
      "Minibatch loss at step 81000: 0.417355\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.8%\n",
      "Minibatch loss at step 81500: 0.360629\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 82000: 0.413833\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 84.3%\n",
      "Minibatch loss at step 82500: 0.268584\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 84.5%\n",
      "Minibatch loss at step 83000: 0.381414\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 83500: 0.345977\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 84000: 0.624057\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 84500: 0.433015\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 85000: 0.236594\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 85500: 0.195628\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 86000: 0.362631\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 86500: 0.339284\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 87000: 0.261577\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 87500: 0.310024\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 88000: 0.280617\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 88500: 0.544766\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 89000: 0.247592\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 89500: 0.375582\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 90000: 0.376785\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 90500: 0.235308\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 91000: 0.470987\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 91500: 0.216397\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 92000: 0.296211\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 92500: 0.425697\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 93000: 0.516194\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 93500: 0.338893\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 94000: 0.130580\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 94500: 0.318840\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 95000: 0.272211\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 95500: 0.335396\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 96000: 0.210288\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 96500: 0.192028\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 97000: 0.435105\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 97500: 0.181012\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 98000: 0.228977\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 98500: 0.264486\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 99000: 0.453040\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 99500: 0.294323\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 100000: 0.314442\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 85.8%\n",
      "Model saved in file: CNN_2.ckpt\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "patch_size1 = 5\n",
    "patch_size2 = 3\n",
    "patch_size3 = 1\n",
    "depth1 = 16\n",
    "depth2 = 32\n",
    "depth3 = 96\n",
    "num_hidden1 = 64\n",
    "num_hidden2 = 32\n",
    "shape=[batch_size, image_size, image_size, num_channels]\n",
    "\n",
    "# Construct a Inception Module CNN.\n",
    "# C1: convolutional layer, batch_size x 28 x 28 x 16, convolution size: 5 x 5 x 1 x 16\n",
    "# P2: max pool layer, batch_size x 14 x 14 x 16\n",
    "# C3: convolutional layer, batch_size x 10 x 10 x 32, convolution size: 5 x 5 x 16 x 32\n",
    "\n",
    "# Inception Module:\n",
    "# Inception & Concat: output batch_size x 5 x 5 x 96\n",
    "# C6: convolutional layer, batch_size x 5 x 5 x 32, convolution size: 1 x 1 x 96 x 32\n",
    "# C7: convolutional layer, batch_size x 1 x 1 x 64, convolution size: 5 x 5 x 32 x 64\n",
    "# Dropout layer\n",
    "# F8: fully-connected layer, weight size: 64 x 16\n",
    "# Output layer, weight size: 16 x 10\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.int64, shape=(batch_size))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.get_variable(\"W1\", shape=[patch_size1, patch_size1, num_channels, depth1],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "  layer1_biases = tf.Variable(tf.constant(1.0, shape=[depth1]), name='B1')\n",
    "\n",
    "  layer2_weights = tf.get_variable(\"W2\", shape=[patch_size1, patch_size1, depth1, depth2],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth2]), name='B2')\n",
    "\n",
    "  layer6_weights = tf.get_variable(\"W6\", shape=[patch_size3, patch_size3, depth3, depth2],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "  layer6_biases = tf.Variable(tf.constant(1.0, shape=[depth2]), name='B6')\n",
    "\n",
    "  layer3_weights = tf.get_variable(\"W3\", shape=[patch_size1, patch_size1, depth2, num_hidden1],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden1]), name='B3')\n",
    "\n",
    "  layer4_weights = tf.get_variable(\"W4\", shape=[num_hidden1, num_hidden2],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden2]), name='B4')\n",
    "\n",
    "  layer5_weights = tf.get_variable(\"W5\", shape=[num_hidden2, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "  layer5_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]), name='B5')\n",
    "    \n",
    "  # Inception Variables.\n",
    "  incep_11_w = tf.get_variable(\"I11W\", shape=[1, 1, depth2, 16],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "  incep_11_b = tf.Variable(tf.constant(1.0, shape=[16]), name='I11B')\n",
    "\n",
    "  incep_12_w = tf.get_variable(\"I12W\", shape=[patch_size1, patch_size1, 16, 32],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "  incep_12_b = tf.Variable(tf.constant(1.0, shape=[32]), name='I12B')\n",
    "\n",
    "  incep_21_w = tf.get_variable(\"I21W\", shape=[1, 1, depth2, 16],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "  incep_21_b = tf.Variable(tf.constant(1.0, shape=[16]), name='I21B')\n",
    "\n",
    "  incep_22_w = tf.get_variable(\"I22W\", shape=[patch_size2, patch_size2, 16, 32],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "  incep_22_b = tf.Variable(tf.constant(1.0, shape=[32]), name='I22B')\n",
    "\n",
    "  incep_31_w = tf.get_variable(\"I31W\", shape=[1, 1, depth2, 16],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "  incep_31_b = tf.Variable(tf.constant(1.0, shape=[16]), name='I31B')\n",
    "\n",
    "  incep_41_w = tf.get_variable(\"I41W\", shape=[1, 1, depth2, 16],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "  incep_41_b = tf.Variable(tf.constant(1.0, shape=[16]), name='I41B')\n",
    "    \n",
    "  # Model.\n",
    "  def model(data, keep_prob, shape):\n",
    "    LCN = LecunLCN(data, shape)\n",
    "    conv = tf.nn.conv2d(LCN, layer1_weights, [1,1,1,1], 'VALID', name='C1')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    lrn = tf.nn.local_response_normalization(hidden)\n",
    "    sub = tf.nn.max_pool(lrn, [1,2,2,1], [1,2,2,1], 'SAME', name='P2')\n",
    "    conv = tf.nn.conv2d(sub, layer2_weights, [1,1,1,1], padding='VALID', name='C3')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    lrn = tf.nn.local_response_normalization(hidden)\n",
    "    \n",
    "    # Inception Module\n",
    "    hidden = Inception(lrn)\n",
    "\n",
    "    conv = tf.nn.conv2d(hidden, layer6_weights, [1,1,1,1], padding='SAME', name='C6')\n",
    "    hidden = tf.nn.relu(conv + layer6_biases)\n",
    "    lrn = tf.nn.local_response_normalization(hidden)\n",
    "    conv = tf.nn.conv2d(lrn, layer3_weights, [1,1,1,1], padding='VALID', name='C7')\n",
    "    hidden = tf.nn.relu(conv + layer3_biases)\n",
    "    lrn = tf.nn.local_response_normalization(hidden)\n",
    "    hidden = tf.nn.dropout(lrn, keep_prob)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])    \n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer4_weights) + layer4_biases)\n",
    "    return tf.matmul(hidden, layer5_weights) + layer5_biases\n",
    "\n",
    "  def Inception(input_tensor):\n",
    "        # Branch 1\n",
    "        conv1 = tf.nn.conv2d(input_tensor, incep_11_w, [1,1,1,1], padding='SAME', name='I1C1')\n",
    "        hidden1 = tf.nn.relu(conv1 + incep_11_b)\n",
    "        lrn1 = tf.nn.local_response_normalization(hidden1)\n",
    "        conv1 = tf.nn.conv2d(lrn1, incep_12_w, [1,2,2,1], padding='SAME', name='I1C2')\n",
    "        hidden1 = tf.nn.relu(conv1 + incep_12_b)\n",
    "        lrn1 = tf.nn.local_response_normalization(hidden1)\n",
    "        # Branch 2\n",
    "        conv2 = tf.nn.conv2d(input_tensor, incep_21_w, [1,1,1,1], padding='SAME', name='I2C1')\n",
    "        hidden2 = tf.nn.relu(conv2 + incep_21_b)\n",
    "        lrn2 = tf.nn.local_response_normalization(hidden2)\n",
    "        conv2 = tf.nn.conv2d(lrn2, incep_22_w, [1,2,2,1], padding='SAME', name='I2C2')\n",
    "        hidden2 = tf.nn.relu(conv2 + incep_22_b)\n",
    "        lrn2 = tf.nn.local_response_normalization(hidden2)\n",
    "        # Branch 3\n",
    "        sub3 = tf.nn.avg_pool(input_tensor, [1,3,3,1], [1,2,2,1], 'SAME', name='I3P1')\n",
    "        conv3 = tf.nn.conv2d(sub3, incep_31_w, [1,1,1,1], padding='SAME', name='I3C2')\n",
    "        hidden3 = tf.nn.relu(conv3 + incep_31_b)\n",
    "        lrn3 = tf.nn.local_response_normalization(hidden3)\n",
    "        # Branch 4\n",
    "        conv4 = tf.nn.conv2d(input_tensor, incep_41_w, [1,2,2,1], padding='SAME', name='I4C1')\n",
    "        hidden4 = tf.nn.relu(conv4 + incep_41_b)\n",
    "        lrn4 = tf.nn.local_response_normalization(hidden4)\n",
    "        # Concat\n",
    "        output_tensor = tf.concat(3, [lrn1, lrn2, lrn3, lrn4], name='CONCAT')\n",
    "        return output_tensor\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset, 1, shape)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  # Optimizer.\n",
    "  #optimizer = tf.train.AdagradOptimizer(0.01).minimize(loss)\n",
    "  global_step = tf.Variable(0)\n",
    "  learning_rate = tf.train.exponential_decay(0.01, global_step, 10000, 0.95)\n",
    "  optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(model(tf_train_dataset, 1.0, shape))\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset, 1.0, shape))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset, 1.0, shape))\n",
    "    \n",
    "  saver = tf.train.Saver()\n",
    "\n",
    "num_steps = 100001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()  \n",
    "  reader = tf.train.NewCheckpointReader(\"CNN_1.ckpt\")\n",
    "  reader.get_variable_to_shape_map()\n",
    "  #saver.restore(session, \"CNN_1.ckpt\")\n",
    "  print(\"Model restored.\")  \n",
    "  \n",
    "  \n",
    "  #tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size)]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    #print(predictions[:])\n",
    "    if (step % 500 == 0): \n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "  save_path = saver.save(session, \"CNN_2.ckpt\")\n",
    "  print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
